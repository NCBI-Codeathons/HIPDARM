# -*- coding: utf-8 -*-
"""hopdarm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uXFYfjt1c911ciBPzJ0ndaNZO77ehXdi
"""

import sklearn
import numpy as np
from sklearn.experimental import enable_hist_gradient_boosting  # noqa
from sklearn.ensemble import HistGradientBoostingClassifier as hGBC
from sklearn.ensemble import RandomForestClassifier as RFC
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
import pandas as pd
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
import matplotlib.pyplot as plt
from sklearn.model_selection import RandomizedSearchCV as RSCV
from time import time
from scipy.stats import randint as sp_randint

X_enc_ceps = pd.read_csv('encoding_filtered2to100Hz_cep.csv').iloc[:,1:901]
y_enc_ceps = pd.read_csv('encoding_filtered2to100Hz_cep.csv').iloc[:,-1]
#enc_ceps_lda = pd.read_csv('encoding_filtered2to100Hz_cep.csv').iloc[:,1:]

X_enc_ceps.head()

print(X_enc_ceps.shape)

pca_enc_ceps = PCA(n_components = 200).fit(X_enc_ceps)

lda_enc_ceps = LDA(n_components = 10).fit(X_enc_ceps,y_enc_ceps)

type(lda_enc_ceps)

pca_enc_ceps_cevr = np.cumsum(pca_enc_ceps.explained_variance_ratio_)
pca_enc_ceps_eigval=pca_enc_ceps.explained_variance_
lda_enc_ceps_cevr = np.cumsum(lda_enc_ceps.explained_variance_ratio_)

xmesh=np.linspace(1,200,200)
lim90=np.zeros(200)+0.9
lim70=np.zeros(200)+0.7
lim80=np.zeros(200)+0.8

plt.figure()

plt.plot(pca_enc_ceps_cevr,marker='o', linewidth=3, markersize=7)
plt.plot(lda_enc_ceps_cevr,marker='v', linewidth=3, markersize=7)

plt.legend(['PCA','LDA'], fontsize=16)

plt.plot(lim70,color='red')
plt.plot(lim80,color='aqua')
plt.plot(lim90,color='green')

plt.xlim([0,100])
plt.ylim([0.0, 1.05])

plt.xticks([3*i for i in range(1,67)], fontsize=8)
plt.yticks([0.1*i for i in range(1,11)], fontsize=8)

plt.xlabel('principle component', fontsize=16)
plt.ylabel('Cumulative explained variance ratio', fontsize=16)

plt.show()

Xpca_trn = np.transpose([np.dot(X_enc_ceps,pca_enc_ceps.components_[i]) for i in range(200)])

X_train, X_test, y_train, y_test = train_test_split(Xpca_trn, y_enc_ceps, test_size=0.33, random_state=42)

clf = RFC(n_estimators = 20)
# Utility function to report best scores
def report(results, n_top=3):
    for i in range(1, n_top + 1):
        candidates = np.flatnonzero(results['rank_test_score'] == i)
        for candidate in candidates:
            print("Model with rank: {0}".format(i))
            print("Mean validation score: {0:.3f} (std: {1:.3f})".format(
                  results['mean_test_score'][candidate],
                  results['std_test_score'][candidate]))
            print("Parameters: {0}".format(results['params'][candidate]))
            print("")


# specify parameters and distributions to sample from
param_dist = {"max_depth": [3, None],
              "max_features": sp_randint(1, 11),
              "min_samples_split": sp_randint(2, 11),
              "bootstrap": [True, False],
              "criterion": ["gini", "entropy"]}

# run randomized search
n_iter_search = 20
random_search = RSCV(clf, param_distributions=param_dist,
                                   n_iter=n_iter_search, cv=8, iid=False)

start = time()
random_search.fit(X_train, y_train)
print("RandomizedSearchCV took %.2f seconds for %d candidates"
      " parameter settings." % ((time() - start), n_iter_search))
report(random_search.cv_results_)

X_ret_ceps = pd.read_csv('retrieval_filtered2to100Hz_cep.csv').iloc[:,1:901]
y_ret_ceps = pd.read_csv('retrieval_filtered2to100Hz_cep.csv').iloc[:,-1]
pca_ret_ceps = PCA(n_components = 200).fit(X_ret_ceps)

Xpca_tst = np.transpose([np.dot(X_ret_ceps,pca_ret_ceps.components_[i]) for i in range(200)])

y_ret_pred = random_search.predict(Xpca_tst)
y_enc_pred = random_search.predict(X_test)

print(y_ret_pred)

acc_ret = 0
for i in range(len(y_ret_pred)):
  if y_ret_pred[i]!=y_ret_ceps[i]:
    acc_ret = acc_ret + 1
     
print('accuracy on retrieval data ',acc_ret/len(y_ret_ceps))

acc_enc=0
wrng_enc_list = []
for i in range(len(y_enc_pred)):
  if y_enc_pred[i]!=y_test.iloc[i]:
    wrng_enc_list.append(i)
    acc_enc = acc_enc + 1
print('accuracy on retrieval data ',1-acc_enc/len(y_test))
print('wrng_enc_list.shape',wrng_enc_list.shape)

from sklearn.metrics import classification_report
print(classification_report(y_test,y_enc_pred))

for i in range(len(y_train)):
  ag = ~()

from sklearn.metrics import roc_curve,roc_auc_score,auc

RF_auroc=roc_auc_score(y_ret_ceps,y_ret_pred)

RF_fpr = dict()
RF_tpr = dict()
RF_roc_auc = dict()
RF_pp = y_ret_pred
RF_fpr[1], RF_tpr[1],thresholds = roc_curve(y_ret_ceps, y_ret_pred)
RF_roc_auc[1] = auc(RF_fpr[1], RF_tpr[1])

#The following plotting script was taken from the scikitlearn's ROC documentation
plt.figure()
lw = 2
plt.plot(RF_fpr[1],RF_tpr[1], color='red',lw=lw, label='RF-ROC curve (area = %0.5f)' % RF_roc_auc[1])

plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([-0.05, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Comparing performance of DT vs LR vs kNN vs SVM')
plt.legend(loc="lower right")
plt.show()
